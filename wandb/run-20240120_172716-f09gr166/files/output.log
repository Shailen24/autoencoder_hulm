
  0%|                                                                                                                                                                                                                | 0/911 [00:00<?, ?it/s]You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.









































 40%|███████████████████████████████████████████████████████████████████████████████                                                                                                                       | 364/911 [01:28<02:27,  3.71it/s]Traceback (most recent call last):
  File "trials.py", line 233, in <module>
    run_trials(data_path=data_paths[i],
  File "trials.py", line 179, in run_trials
    best_trial = trainer.hyperparameter_search(
  File "/chronos_data/ssmith/lib/python3.8/site-packages/transformers/trainer.py", line 2633, in hyperparameter_search
    best_run = backend_obj.run(self, n_trials, direction, **kwargs)
  File "/chronos_data/ssmith/lib/python3.8/site-packages/transformers/hyperparameter_search.py", line 72, in run
    return run_hp_search_optuna(trainer, n_trials, direction, **kwargs)
  File "/chronos_data/ssmith/lib/python3.8/site-packages/transformers/integrations/integration_utils.py", line 211, in run_hp_search_optuna
    study.optimize(_objective, n_trials=n_trials, timeout=timeout, n_jobs=n_jobs)
  File "/chronos_data/ssmith/lib/python3.8/site-packages/optuna/study/study.py", line 451, in optimize
    _optimize(
  File "/chronos_data/ssmith/lib/python3.8/site-packages/optuna/study/_optimize.py", line 66, in _optimize
    _optimize_sequential(
  File "/chronos_data/ssmith/lib/python3.8/site-packages/optuna/study/_optimize.py", line 163, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/chronos_data/ssmith/lib/python3.8/site-packages/optuna/study/_optimize.py", line 229, in _run_trial
    _log_failed_trial(
  File "/chronos_data/ssmith/lib/python3.8/site-packages/optuna/study/_optimize.py", line 261, in _log_failed_trial
    _logger.warning(
  File "/usr/lib/python3.8/logging/__init__.py", line 1458, in warning
    self._log(WARNING, msg, args, **kwargs)
  File "/usr/lib/python3.8/logging/__init__.py", line 1589, in _log
    self.handle(record)
  File "/usr/lib/python3.8/logging/__init__.py", line 1599, in handle
    self.callHandlers(record)
  File "/usr/lib/python3.8/logging/__init__.py", line 1661, in callHandlers
    hdlr.handle(record)
  File "/usr/lib/python3.8/logging/__init__.py", line 954, in handle
    self.emit(record)
  File "/usr/lib/python3.8/logging/__init__.py", line 1085, in emit
    msg = self.format(record)
  File "/usr/lib/python3.8/logging/__init__.py", line 929, in format
    return fmt.format(record)
  File "/usr/lib/python3.8/logging/__init__.py", line 676, in format
    record.exc_text = self.formatException(record.exc_info)
  File "/usr/lib/python3.8/logging/__init__.py", line 626, in formatException
    traceback.print_exception(ei[0], ei[1], tb, None, sio)
  File "/usr/lib/python3.8/traceback.py", line 103, in print_exception
    for line in TracebackException(
  File "/usr/lib/python3.8/traceback.py", line 508, in __init__
    self.stack = StackSummary.extract(
  File "/usr/lib/python3.8/traceback.py", line 366, in extract
    f.line
  File "/usr/lib/python3.8/traceback.py", line 288, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/usr/lib/python3.8/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/usr/lib/python3.8/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/usr/lib/python3.8/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
  File "/usr/lib/python3.8/tokenize.py", line 394, in open
    encoding, lines = detect_encoding(buffer.readline)
  File "/usr/lib/python3.8/tokenize.py", line 363, in detect_encoding
    first = read_or_stop()
  File "/usr/lib/python3.8/tokenize.py", line 321, in read_or_stop
    return readline()
KeyboardInterrupt
Traceback (most recent call last):
  File "trials.py", line 233, in <module>
    run_trials(data_path=data_paths[i],
  File "trials.py", line 179, in run_trials
    best_trial = trainer.hyperparameter_search(
  File "/chronos_data/ssmith/lib/python3.8/site-packages/transformers/trainer.py", line 2633, in hyperparameter_search
    best_run = backend_obj.run(self, n_trials, direction, **kwargs)
  File "/chronos_data/ssmith/lib/python3.8/site-packages/transformers/hyperparameter_search.py", line 72, in run
    return run_hp_search_optuna(trainer, n_trials, direction, **kwargs)
  File "/chronos_data/ssmith/lib/python3.8/site-packages/transformers/integrations/integration_utils.py", line 211, in run_hp_search_optuna
    study.optimize(_objective, n_trials=n_trials, timeout=timeout, n_jobs=n_jobs)
  File "/chronos_data/ssmith/lib/python3.8/site-packages/optuna/study/study.py", line 451, in optimize
    _optimize(
  File "/chronos_data/ssmith/lib/python3.8/site-packages/optuna/study/_optimize.py", line 66, in _optimize
    _optimize_sequential(
  File "/chronos_data/ssmith/lib/python3.8/site-packages/optuna/study/_optimize.py", line 163, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/chronos_data/ssmith/lib/python3.8/site-packages/optuna/study/_optimize.py", line 229, in _run_trial
    _log_failed_trial(
  File "/chronos_data/ssmith/lib/python3.8/site-packages/optuna/study/_optimize.py", line 261, in _log_failed_trial
    _logger.warning(
  File "/usr/lib/python3.8/logging/__init__.py", line 1458, in warning
    self._log(WARNING, msg, args, **kwargs)
  File "/usr/lib/python3.8/logging/__init__.py", line 1589, in _log
    self.handle(record)
  File "/usr/lib/python3.8/logging/__init__.py", line 1599, in handle
    self.callHandlers(record)
  File "/usr/lib/python3.8/logging/__init__.py", line 1661, in callHandlers
    hdlr.handle(record)
  File "/usr/lib/python3.8/logging/__init__.py", line 954, in handle
    self.emit(record)
  File "/usr/lib/python3.8/logging/__init__.py", line 1085, in emit
    msg = self.format(record)
  File "/usr/lib/python3.8/logging/__init__.py", line 929, in format
    return fmt.format(record)
  File "/usr/lib/python3.8/logging/__init__.py", line 676, in format
    record.exc_text = self.formatException(record.exc_info)
  File "/usr/lib/python3.8/logging/__init__.py", line 626, in formatException
    traceback.print_exception(ei[0], ei[1], tb, None, sio)
  File "/usr/lib/python3.8/traceback.py", line 103, in print_exception
    for line in TracebackException(
  File "/usr/lib/python3.8/traceback.py", line 508, in __init__
    self.stack = StackSummary.extract(
  File "/usr/lib/python3.8/traceback.py", line 366, in extract
    f.line
  File "/usr/lib/python3.8/traceback.py", line 288, in line
    self._line = linecache.getline(self.filename, self.lineno).strip()
  File "/usr/lib/python3.8/linecache.py", line 16, in getline
    lines = getlines(filename, module_globals)
  File "/usr/lib/python3.8/linecache.py", line 47, in getlines
    return updatecache(filename, module_globals)
  File "/usr/lib/python3.8/linecache.py", line 136, in updatecache
    with tokenize.open(fullname) as fp:
  File "/usr/lib/python3.8/tokenize.py", line 394, in open
    encoding, lines = detect_encoding(buffer.readline)
  File "/usr/lib/python3.8/tokenize.py", line 363, in detect_encoding
    first = read_or_stop()
  File "/usr/lib/python3.8/tokenize.py", line 321, in read_or_stop
    return readline()
KeyboardInterrupt