
  0%|                                                                                                                                                                                                                 | 0/50 [00:00<?, ?it/s]You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.







100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:17<00:00,  2.79it/s]



 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 6/7 [00:03<00:00,  1.34it/s]
{'eval_loss': 6.138835430145264, 'eval_runtime': 6.4881, 'eval_samples_per_second': 7.706, 'eval_steps_per_second': 1.079, 'epoch': 1.0}
There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:27<00:00,  1.80it/s]
[32m[I 2024-01-19 15:06:32,870][39m Trial 0 finished with value: 6.138835430145264 and parameters: {'learning_rate': 0.0001477124026235475}. Best is trial 0 with value: 6.138835430145264.
{'eval_loss': 6.138835430145264, 'eval_runtime': 6.4881, 'eval_samples_per_second': 7.706, 'eval_steps_per_second': 1.079, 'epoch': 1.0, 'perplexity': 463.51346261760136, 'trial_params': '{"learning_rate": 0.0001477124026235475}'} /cronus_data/ssmith/models/blogsUD/optuna_wandb_test/run-0
{'train_runtime': 29.7011, 'train_samples_per_second': 1.683, 'train_steps_per_second': 1.683, 'train_loss': 6.500156860351563, 'epoch': 1.0}
pos embds stdev:  tensor(0.0662, grad_fn=<StdBackward0>)